---
title: LLM æ¶æ„--RAG
author: ç‹å“²å³°
date: '2024-03-23'
slug: llm-rag
categories:
  - nlp
  - deeplearning
tags:
  - model
---

<style>
details {
    border: 1px solid #aaa;
    border-radius: 4px;
    padding: .5em .5em 0;
}
summary {
    font-weight: bold;
    margin: -.5em -.5em 0;
    padding: .5em;
}
details[open] {
    padding: .5em;
}
details[open] summary {
    border-bottom: 1px solid #aaa;
    margin-bottom: .5em;
}
img {
    pointer-events: none;
}
</style>

<details><summary>ç›®å½•</summary><p>

- [RAG ä»‹ç»](#rag-ä»‹ç»)
     - [LLM é—®é¢˜](#llm-é—®é¢˜)
     - [RAG åŸç†](#rag-åŸç†)
     - [RAG å’Œ Fine-tune å¯¹æ¯”](#rag-å’Œ-fine-tune-å¯¹æ¯”)
- [RAG æµç¨‹](#rag-æµç¨‹)
- [RAG æ¨¡å—](#rag-æ¨¡å—)
     - [å‘é‡åŒ–](#å‘é‡åŒ–)
     - [æ–‡æ¡£åŠ è½½å’Œåˆ‡åˆ†](#æ–‡æ¡£åŠ è½½å’Œåˆ‡åˆ†)
     - [æ•°æ®åº“å’Œå‘é‡æ£€ç´¢](#æ•°æ®åº“å’Œå‘é‡æ£€ç´¢)
     - [å¤§æ¨¡å‹æ¨¡å—](#å¤§æ¨¡å‹æ¨¡å—)
- [RAG ç»„ä»¶-LangChian](#rag-ç»„ä»¶-langchian)
     - [LangChain ä¸­çš„ RAG ç»„ä»¶](#langchain-ä¸­çš„-rag-ç»„ä»¶)
     - [LLM æ¥å…¥ LangChain](#llm-æ¥å…¥-langchain)
          - [åŸºäº LangChain è°ƒç”¨ ChatGPT](#åŸºäº-langchain-è°ƒç”¨-chatgpt)
               - [Model](#model)
               - [Prompt](#prompt)
               - [Output parser](#output-parser)
               - [å®Œæ•´çš„æµç¨‹](#å®Œæ•´çš„æµç¨‹)
          - [ä½¿ç”¨ LangChain è°ƒç”¨æ–‡å¿ƒä¸€è¨€](#ä½¿ç”¨-langchain-è°ƒç”¨æ–‡å¿ƒä¸€è¨€)
               - [è‡ªå®šä¹‰ LLM æ¥å…¥ langchain](#è‡ªå®šä¹‰-llm-æ¥å…¥-langchain)
               - [åœ¨ langchain ç›´æ¥è°ƒç”¨æ–‡å¿ƒä¸€è¨€](#åœ¨-langchain-ç›´æ¥è°ƒç”¨æ–‡å¿ƒä¸€è¨€)
          - [ä½¿ç”¨ LangChain è°ƒç”¨è®¯é£æ˜Ÿç«](#ä½¿ç”¨-langchain-è°ƒç”¨è®¯é£æ˜Ÿç«)
          - [ä½¿ç”¨ LangChain è°ƒç”¨æ™ºè°± GLM](#ä½¿ç”¨-langchain-è°ƒç”¨æ™ºè°±-glm)
               - [è‡ªå®šä¹‰ chatglm](#è‡ªå®šä¹‰-chatglm)
               - [è‡ªå®šä¹‰ chatglm æ¥å…¥ LangChain](#è‡ªå®šä¹‰-chatglm-æ¥å…¥-langchain)
     - [åŸºäº LangChain æ„å»ºæ£€ç´¢é—®ç­”é“¾](#åŸºäº-langchain-æ„å»ºæ£€ç´¢é—®ç­”é“¾)
          - [åŠ è½½æ•°æ®åº“å‘é‡](#åŠ è½½æ•°æ®åº“å‘é‡)
          - [åˆ›å»ºä¸€ä¸ª LLM](#åˆ›å»ºä¸€ä¸ª-llm)
          - [æ„å»ºæ£€ç´¢é—®ç­”é“¾](#æ„å»ºæ£€ç´¢é—®ç­”é“¾)
          - [æ£€ç´¢é—®ç­”é“¾æ•ˆæœæµ‹è¯•](#æ£€ç´¢é—®ç­”é“¾æ•ˆæœæµ‹è¯•)
          - [æ·»åŠ å†å²å¯¹è¯çš„è®°å¿†åŠŸèƒ½](#æ·»åŠ å†å²å¯¹è¯çš„è®°å¿†åŠŸèƒ½)
     - [åŸºäº Streamlit éƒ¨ç½²çŸ¥è¯†åº“åŠ©æ‰‹](#åŸºäº-streamlit-éƒ¨ç½²çŸ¥è¯†åº“åŠ©æ‰‹)
          - [æ„å»ºåº”ç”¨ç¨‹åº](#æ„å»ºåº”ç”¨ç¨‹åº)
          - [æ·»åŠ æ£€ç´¢å›ç­”](#æ·»åŠ æ£€ç´¢å›ç­”)
          - [éƒ¨ç½²åº”ç”¨ç¨‹åº](#éƒ¨ç½²åº”ç”¨ç¨‹åº)
- [RAG ç»„ä»¶-LlamaIndex](#rag-ç»„ä»¶-llamaindex)
- [RAG ç»„ä»¶-dify](#rag-ç»„ä»¶-dify)
- [å‚è€ƒ](#å‚è€ƒ)
</p></details><p></p>

# RAG ä»‹ç»

## LLM é—®é¢˜

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç›¸è¾ƒäºä¼ ç»Ÿçš„è¯­è¨€æ¨¡å‹å…·æœ‰æ›´å¼ºå¤§çš„èƒ½åŠ›ï¼Œç„¶è€Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œ
å®ƒä»¬ä»å¯èƒ½æ— æ³•æä¾›å‡†ç¡®çš„ç­”æ¡ˆã€‚ç”±äºè®­ç»ƒè¿™äº›æ¨¡å‹éœ€è¦è€—è´¹å¤§é‡æ—¶é—´ï¼Œ
å› æ­¤å®ƒä»¬æ‰€ä¾èµ–çš„æ•°æ®å¯èƒ½å·²ç»è¿‡æ—¶ã€‚æ­¤å¤–ï¼Œå¤§æ¨¡å‹è™½ç„¶èƒ½å¤Ÿç†è§£äº’è”ç½‘ä¸Šçš„é€šç”¨äº‹å®ï¼Œ
ä½†å¾€å¾€ç¼ºä¹å¯¹ç‰¹å®šé¢†åŸŸæˆ–ä¼ä¸šä¸“æœ‰æ•°æ®çš„äº†è§£ï¼Œè€Œè¿™äº›æ•°æ®å¯¹äºæ„å»ºåŸºäº AI çš„åº”ç”¨è‡³å…³é‡è¦ã€‚

åœ¨å¤§æ¨¡å‹å‡ºç°ä¹‹å‰ï¼Œ**å¾®è°ƒ(fine-tuning)** æ˜¯ä¸€ç§å¸¸ç”¨çš„æ‰©å±•æ¨¡å‹èƒ½åŠ›çš„æ–¹æ³•ã€‚
ç„¶è€Œï¼Œéšç€æ¨¡å‹è§„æ¨¡çš„æ‰©å¤§å’Œè®­ç»ƒæ•°æ®æ•°æ®é‡çš„å¢åŠ ï¼Œå¾®è°ƒå˜å¾—è¶Šæ¥è¶Šä¸é€‚ç”¨äºå¤§å¤šæ•°æƒ…å†µï¼Œ
é™¤ééœ€è¦æ¨¡å‹ä»¥æŒ‡å®šé£æ ¼è¿›è¡Œäº¤æµæˆ–å……å½“é¢†åŸŸä¸“å®¶çš„è§’è‰²ï¼Œ
ä¸€ä¸ªæ˜¾è‘—çš„ä¾‹å­æ˜¯ OpenAI å°†è¡¥å…¨æ¨¡å‹ GPT-3.5 æ”¹è¿›ä¸ºæ–°çš„èŠå¤©æ¨¡å‹ ChatGPTï¼Œ
å¾®è°ƒæ•ˆæœå‡ºè‰²ã€‚å¾®è°ƒä¸ä»…éœ€è¦å¤§é‡çš„é«˜è´¨é‡æ•°æ®ï¼Œè¿˜æ¶ˆè€—å·¨å¤§çš„è®¡ç®—èµ„æºå’Œæ—¶é—´ï¼Œ
è¿™å¯¹äºè®¸å¤šä¸ªäººå’Œä¼ä¸šç”¨æˆ·æ¥è¯´æ˜¯æ˜‚è´µä¸”ç¨€ç¼ºçš„èµ„æºã€‚
å› æ­¤ï¼Œç ”ç©¶å¦‚ä½•æœ‰æ•ˆåœ°åˆ©ç”¨ä¸“æœ‰æ•°æ®æ¥è¾…åŠ©å¤§æ¨¡å‹ç”Ÿæˆå†…å®¹ï¼Œæˆä¸ºäº†å­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œçš„ä¸€ä¸ªé‡è¦é¢†åŸŸã€‚
è¿™ä¸ä»…èƒ½å¤Ÿæé«˜æ¨¡å‹çš„å®ç”¨æ€§ï¼Œè¿˜èƒ½å¤Ÿå‡è½»å¯¹å¾®è°ƒçš„ä¾èµ–ï¼Œä½¿å¾— AI åº”ç”¨æ›´åŠ é«˜æ•ˆå’Œç»æµã€‚

ç›®å‰ LLM é¢ä¸´çš„ä¸»è¦é—®é¢˜ä»¥åŠ RAG çš„ä½œç”¨ï¼š

* ä¿¡æ¯åå·®/å¹»è§‰ï¼šLLM æœ‰æ—¶ä¼šäº§ç”Ÿä¸å®¢è§‚äº‹å®ä¸ç¬¦çš„ä¿¡æ¯ï¼Œå¯¼è‡´ç”¨æˆ·æ¥æ”¶åˆ°çš„ä¿¡æ¯ä¸å‡†ç¡®ã€‚
  RAG é€šè¿‡æ£€ç´¢æ•°æ®æºï¼Œè¾…åŠ©æ¨¡å‹ç”Ÿæˆè¿‡ç¨‹ï¼Œç¡®ä¿è¾“å‡ºå†…å®¹çš„ç²¾ç¡®æ€§å’Œå¯ä¿¡åº¦ï¼Œå‡å°‘ä¿¡æ¯åå·®ã€‚
* çŸ¥è¯†æ›´æ–°æ»åæ€§ï¼šLLM åŸºäºé™æ€çš„æ•°æ®é›†è®­ç»ƒï¼Œè¿™å¯èƒ½å¯¼è‡´æ¨¡å‹çš„çŸ¥è¯†æ›´æ–°æ»åï¼Œ
  æ— æ³•åŠæ—¶åæ˜ æœ€æ–°çš„ä¿¡æ¯åŠ¨æ€ã€‚RAG é€šè¿‡å®æ—¶æ£€ç´¢æœ€æ–°æ•°æ®ï¼Œä¿æŒå†…å®¹çš„æ—¶æ•ˆæ€§ï¼Œç¡®ä¿ä¿¡æ¯çš„æŒç»­æ›´æ–°å’Œå‡†ç¡®æ€§ã€‚
* å†…å®¹ä¸å¯è¿½æº¯ï¼šLLM ç”Ÿæˆçš„å†…å®¹å¾€å¾€ç¼ºä¹æ˜ç¡®çš„ä¿¡æ¯æ¥æºï¼Œå½±å“å†…å®¹çš„å¯ä¿¡åº¦ã€‚
  RAG å°†ç”Ÿæˆå†…å®¹ä¸æ£€ç´¢åˆ°çš„åŸå§‹èµ„æ–™å»ºç«‹é“¾æ¥ï¼Œå¢å¼ºäº†å†…å®¹çš„å¯è¿½æº¯æ€§ï¼Œä»è€Œæå‡äº†ç”¨æˆ·å¯¹ç”Ÿæˆå†…å®¹çš„ä¿¡ä»»åº¦ã€‚
* é¢†åŸŸä¸“ä¸šçŸ¥è¯†èƒ½åŠ›æ¬ ç¼ºï¼šLLM åœ¨å¤„ç†ç‰¹å®šé¢†åŸŸçš„ä¸“ä¸šçŸ¥è¯†æ—¶ï¼Œæ•ˆæœå¯èƒ½ä¸å¤ªç†æƒ³ï¼Œ
  è¿™å¯èƒ½ä¼šå½±å“åˆ°å…¶åœ¨ç›¸å…³é¢†åŸŸçš„å›ç­”è´¨é‡ã€‚RAG é€šè¿‡æ£€ç´¢ç‰¹å®šé¢†åŸŸçš„ç›¸å…³æ–‡æ¡£ï¼Œ
  ä¸ºæ¨¡å‹æä¾›ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»è€Œæå‡äº†åœ¨ä¸“ä¸šé¢†åŸŸå†…çš„é—®é¢˜å›ç­”è´¨é‡å’Œæ·±åº¦ã€‚
* æ¨ç†èƒ½åŠ›é™åˆ¶ï¼šé¢å¯¹å¤æ‚é—®é¢˜æ—¶ï¼ŒLLM å¯èƒ½ç¼ºä¹å¿…è¦çš„æ¨ç†èƒ½åŠ›ï¼Œè¿™å½±å“äº†å…¶å¯¹é—®é¢˜çš„ç†è§£å’Œå›ç­”ã€‚
  RAG ç»“åˆæ£€ç´¢åˆ°çš„ä¿¡æ¯å’Œæ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ï¼Œé€šè¿‡æä¾›é¢å¤–çš„èƒŒæ™¯çŸ¥è¯†å’Œæ•°æ®æ”¯æŒï¼Œå¢å¼ºäº†æ¨¡å‹çš„æ¨ç†å’Œç†è§£èƒ½åŠ›ã€‚
* åº”ç”¨åœºæ™¯é€‚åº”æ€§å—é™ï¼šLLM éœ€åœ¨å¤šæ ·åŒ–çš„åº”ç”¨åœºæ™¯ä¸­ä¿æŒé«˜æ•ˆå’Œå‡†ç¡®ï¼Œ
  ä½†å•ä¸€æ¨¡å‹å¯èƒ½éš¾ä»¥å…¨é¢é€‚åº”æ‰€æœ‰åœºæ™¯ã€‚RAG ä½¿å¾— LLM èƒ½å¤Ÿé€šè¿‡æ£€ç´¢å¯¹åº”åº”ç”¨åœºæ™¯æ•°æ®çš„æ–¹å¼ï¼Œ
  çµæ´»é€‚åº”é—®ç­”ç³»ç»Ÿã€æ¨èç³»ç»Ÿç­‰å¤šç§åº”ç”¨åœºæ™¯ã€‚
* é•¿æ–‡æœ¬å¤„ç†èƒ½åŠ›è¾ƒå¼±ï¼š LLM åœ¨ç†è§£å’Œç”Ÿæˆé•¿ç¯‡å†…å®¹æ—¶å—é™äºæœ‰é™çš„ä¸Šä¸‹æ–‡çª—å£ï¼Œ
  ä¸”å¿…é¡»æŒ‰é¡ºåºå¤„ç†å†…å®¹ï¼Œè¾“å…¥è¶Šé•¿ï¼Œé€Ÿåº¦è¶Šæ…¢ã€‚RAG é€šè¿‡æ£€ç´¢å’Œæ•´åˆé•¿æ–‡æœ¬ä¿¡æ¯ï¼Œ
  å¼ºåŒ–äº†æ¨¡å‹å¯¹é•¿ä¸Šä¸‹æ–‡çš„ç†è§£å’Œç”Ÿæˆï¼Œæœ‰æ•ˆçªç ´äº†è¾“å…¥é•¿åº¦çš„é™åˆ¶ï¼ŒåŒæ—¶é™ä½äº†è°ƒç”¨æˆæœ¬ï¼Œå¹¶æå‡äº†æ•´ä½“çš„å¤„ç†æ•ˆç‡ã€‚

## RAG åŸç†

ä¸ºäº†è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆæ–‡æœ¬æ—¶é¢ä¸´çš„ä¸€ç³»åˆ—æŒ‘æˆ˜ï¼Œæé«˜æ¨¡å‹çš„æ€§èƒ½å’Œè¾“å‡ºè´¨é‡ï¼Œ
ç ”ç©¶äººå‘˜æå‡ºäº†ä¸€ç§æ–°çš„æ¨¡å‹æ¶æ„ï¼š**æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG, Retrieval-Augmented Generation)**ã€‚
è¯¥æ¶æ„å·§å¦™åœ° **æ•´åˆäº†ä»åºå¤§çŸ¥è¯†åº“ä¸­æ£€ç´¢åˆ°çš„ç›¸å…³ä¿¡æ¯ï¼Œå¹¶ä»¥æ­¤ä¸ºåŸºç¡€ï¼ŒæŒ‡å¯¼å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆæ›´ä¸ºç²¾å‡†çš„ç­”æ¡ˆ**ï¼Œ
å³ï¼šRAG çš„ä½œç”¨æ˜¯ **å¸®åŠ©æ¨¡å‹æŸ¥æ‰¾å¤–éƒ¨ä¿¡æ¯ä»¥æ”¹å–„å…¶å“åº”**ï¼Œä»è€Œæ˜¾è‘—æå‡äº†å›ç­”çš„å‡†ç¡®æ€§ä¸æ·±åº¦ã€‚

RAG æŠ€æœ¯åŸºäº **æç¤ºè¯(prompt)**ï¼Œæœ€æ—©ç”± Facebook AI ç ”ç©¶æœºæ„(FAIR)ä¸å…¶åˆä½œè€…äº 2021 å¹´å‘å¸ƒçš„è®ºæ–‡ â€œRetrieval-Augmented Generation for Knowledge-Intensive NLP Tasksâ€ ä¸­æå‡ºã€‚
RAG æœ‰æ•ˆåœ°ç¼“è§£äº†å¹»è§‰é—®é¢˜ï¼Œæé«˜äº†çŸ¥è¯†æ›´æ–°çš„é€Ÿåº¦ï¼Œå¹¶å¢å¼ºäº†å†…å®¹ç”Ÿæˆçš„å¯è¿½æº¯æ€§ï¼Œ
ä½¿å¾—å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­å˜å¾—æ›´åŠ å®ç”¨å’Œå¯ä¿¡ã€‚

RAG æŠ€æœ¯ååˆ†å¼ºå¤§ï¼Œå®ƒå·²ç»è¢«å¿…åº”æœç´¢ã€ç™¾åº¦æœç´¢ä»¥åŠå…¶ä»–å¤§å…¬å¸çš„äº§å“æ‰€é‡‡ç”¨ï¼Œæ—¨åœ¨å°†æœ€æ–°çš„æ•°æ®èå…¥å…¶æ¨¡å‹ã€‚
åœ¨æ²¡æœ‰å¤§é‡æ–°æ•°æ®ã€é¢„ç®—æœ‰é™æˆ–æ—¶é—´ç´§å¼ çš„æƒ…å†µä¸‹ï¼Œè¿™ç§æ–¹æ³•ä¹Ÿèƒ½å–å¾—ä¸é”™çš„æ•ˆæœï¼Œè€Œä¸”å®ƒçš„åŸç†è¶³å¤Ÿç®€å•ã€‚

## RAG å’Œ Fine-tune å¯¹æ¯”

åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹æ•ˆæœä¸­ï¼ŒRAG å’Œ å¾®è°ƒ(Fine-tune)æ˜¯ä¸¤ç§ä¸»æµçš„æ–¹æ³•ï¼š

* RAG ç»“åˆäº† **æ£€ç´¢ï¼ˆä»å¤§å‹æ–‡æ¡£ç³»ç»Ÿä¸­è·å–ç›¸å…³æ–‡æ¡£ç‰‡æ®µï¼‰** å’Œ **ç”Ÿæˆï¼ˆæ¨¡å‹ä½¿ç”¨è¿™äº›ç‰‡æ®µä¸­çš„ä¿¡æ¯ç”Ÿæˆç­”æ¡ˆï¼‰** ä¸¤éƒ¨åˆ†ã€‚
  RAG é€šè¿‡åœ¨è¯­è¨€æ¨¡å‹ç”Ÿæˆç­”æ¡ˆä¹‹å‰ï¼Œå…ˆä»å¹¿æ³›çš„æ–‡æ¡£æ•°æ®åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ï¼Œç„¶ååˆ©ç”¨è¿™äº›ä¿¡æ¯æ¥å¼•å¯¼ç”Ÿæˆè¿‡ç¨‹ï¼Œ
  æå¤§åœ°æå‡äº†å†…å®¹çš„å‡†ç¡®æ€§ã€‚
* å¾®è°ƒé€šè¿‡åœ¨ç‰¹å®šæ•°æ®é›†ä¸Šè¿›ä¸€æ­¥è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹ï¼Œæ¥æå‡æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚

RAG å’Œ å¾®è°ƒçš„å¯¹æ¯”å¯ä»¥å‚è€ƒä¸‹è¡¨ï¼š

| ç‰¹å¾æ¯”è¾ƒ | RAG                                                                    | å¾®è°ƒ                                                                       |
| -------- | ---------------------------------------------------------------------- | -------------------------------------------------------------------------- |
| çŸ¥è¯†æ›´æ–° | ç›´æ¥æ›´æ–°æ£€ç´¢çŸ¥è¯†åº“ï¼Œæ— éœ€é‡æ–°è®­ç»ƒã€‚ä¿¡æ¯æ›´æ–°æˆæœ¬ä½ï¼Œé€‚åˆåŠ¨æ€å˜åŒ–çš„æ•°æ®ã€‚ | é€šå¸¸éœ€è¦é‡æ–°è®­ç»ƒæ¥ä¿æŒçŸ¥è¯†å’Œæ•°æ®çš„æ›´æ–°ã€‚æ›´æ–°æˆæœ¬é«˜ï¼Œé€‚åˆé™æ€æ•°æ®ã€‚         |
| å¤–éƒ¨çŸ¥è¯† | æ“…é•¿åˆ©ç”¨å¤–éƒ¨èµ„æºï¼Œç‰¹åˆ«é€‚åˆå¤„ç†æ–‡æ¡£æˆ–å…¶ä»–ç»“æ„åŒ–/éç»“æ„åŒ–æ•°æ®åº“ã€‚        | å°†å¤–éƒ¨çŸ¥è¯†å­¦ä¹ åˆ° LLM å†…éƒ¨ã€‚                                                |
| æ•°æ®å¤„ç† | å¯¹æ•°æ®çš„å¤„ç†å’Œæ“ä½œè¦æ±‚æä½ã€‚                                           | ä¾èµ–äºæ„å»ºé«˜è´¨é‡çš„æ•°æ®é›†ï¼Œæœ‰é™çš„æ•°æ®é›†å¯èƒ½æ— æ³•æ˜¾è‘—æé«˜æ€§èƒ½ã€‚               |
| æ¨¡å‹å®šåˆ¶ | ä¾§é‡äºä¿¡æ¯æ£€ç´¢å’Œèåˆå¤–éƒ¨çŸ¥è¯†ï¼Œä½†å¯èƒ½æ— æ³•å……åˆ†å®šåˆ¶æ¨¡å‹è¡Œä¸ºæˆ–å†™ä½œé£æ ¼ã€‚   | å¯ä»¥æ ¹æ®ç‰¹å®šé£æ ¼æˆ–æœ¯è¯­è°ƒæ•´ LLM è¡Œä¸ºã€å†™ä½œé£æ ¼æˆ–ç‰¹å®šé¢†åŸŸçŸ¥è¯†ã€‚              |
| å¯è§£é‡Šæ€§ | å¯ä»¥è¿½æº¯åˆ°å…·ä½“çš„æ•°æ®æ¥æºï¼Œæœ‰è¾ƒå¥½çš„å¯è§£é‡Šæ€§å’Œå¯è¿½è¸ªæ€§ã€‚                 | é»‘ç›’å­ï¼Œå¯è§£é‡Šæ€§ç›¸å¯¹è¾ƒä½ã€‚                                                 |
| è®¡ç®—èµ„æº | éœ€è¦é¢å¤–çš„èµ„æºæ¥æ”¯æŒæ£€ç´¢æœºåˆ¶å’Œæ•°æ®åº“çš„ç»´æŠ¤ã€‚                           | ä¾èµ–é«˜è´¨é‡çš„è®­ç»ƒæ•°æ®é›†å’Œå¾®è°ƒç›®æ ‡ï¼Œå¯¹è®¡ç®—èµ„æºçš„è¦æ±‚è¾ƒé«˜ã€‚                   |
| æ¨ç†å»¶è¿Ÿ | å¢åŠ äº†æ£€ç´¢æ­¥éª¤çš„è€—æ—¶                                                   | å•çº¯ LLM ç”Ÿæˆçš„è€—æ—¶                                                        |
| é™ä½å¹»è§‰ | é€šè¿‡æ£€ç´¢åˆ°çš„çœŸå®ä¿¡æ¯ç”Ÿæˆå›ç­”ï¼Œé™ä½äº†äº§ç”Ÿå¹»è§‰çš„æ¦‚ç‡ã€‚                   | æ¨¡å‹å­¦ä¹ ç‰¹å®šé¢†åŸŸçš„æ•°æ®æœ‰åŠ©äºå‡å°‘å¹»è§‰ï¼Œä½†é¢å¯¹æœªè§è¿‡çš„è¾“å…¥æ—¶ä»å¯èƒ½å‡ºç°å¹»è§‰ã€‚ |
| ä¼¦ç†éšç§ | æ£€ç´¢å’Œä½¿ç”¨å¤–éƒ¨æ•°æ®å¯èƒ½å¼•å‘ä¼¦ç†å’Œéšç§æ–¹é¢çš„é—®é¢˜ã€‚                       | è®­ç»ƒæ•°æ®ä¸­çš„æ•æ„Ÿä¿¡æ¯éœ€è¦å¦¥å–„å¤„ç†ï¼Œä»¥é˜²æ³„éœ²ã€‚                               |

# RAG æµç¨‹

RAG æŠ€æœ¯åœ¨å…·ä½“å®ç°æ–¹å¼ä¸Šå¯èƒ½æœ‰æ‰€å˜åŒ–ï¼Œä½†åœ¨æ¦‚å¿µå±‚é¢ï¼Œå°†å…¶èå…¥åº”ç”¨é€šå¸¸åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼ˆè§ä¸‹å›¾ï¼‰ï¼š

![img](images/RAG.png)

![img](images/RAG-APP.png)

1. ç”¨æˆ·æäº¤ä¸€ä¸ªé—®é¢˜
2. RAG ç³»ç»Ÿæœç´¢å¯èƒ½å›ç­”è¿™ä¸ªé—®é¢˜çš„ç›¸å…³æ–‡æ¡£ã€‚è¿™äº›æ–‡æ¡£é€šå¸¸åŒ…å«äº†ä¸“æœ‰æ•°æ®ï¼Œ
   å¹¶è¢«å­˜å‚¨åœ¨æŸç§å½¢å¼çš„æ–‡æ¡£ç´¢å¼•é‡Œ
3. RAG ç³»ç»Ÿæ„å»ºä¸€ä¸ªæç¤ºè¯ï¼Œå®ƒç»“åˆäº†ç”¨æˆ·è¾“å…¥ã€ç›¸å…³æ–‡æ¡£ä»¥åŠå¯¹å¤§æ¨¡å‹çš„æç¤ºè¯ï¼Œ
   å¼•å¯¼å…¶ä½¿ç”¨ç›¸å…³æ–‡æ¡£æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜
4. RAG ç³»ç»Ÿå°†è¿™ä¸ªæç¤ºè¯å‘é€ç»™å¤§æ¨¡å‹
5. å¤§æ¨¡å‹åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡è¿”å›å¯¹ç”¨æˆ·é—®é¢˜çš„å›ç­”ï¼Œè¿™å°±æ˜¯ç³»ç»Ÿçš„è¾“å‡ºç»“æœ

RAG æ˜¯ä¸€ä¸ªå®Œæ•´çš„ç³»ç»Ÿï¼Œå…¶å…·ä½“å®ç°æ–¹å¼ä¸ŠåŸºæœ¬æµç¨‹æ˜¯ï¼š

![img](images/C1-2-RAG.png)

1. æ•°æ®å¤„ç†
    - å¯¹åŸå§‹æ•°æ®è¿›è¡Œæ¸…æ´—å’Œå¤„ç†
    - å°†å¤„ç†åçš„æ•°æ®è½¬åŒ–ä¸ºæ£€ç´¢æ¨¡å‹å¯ä»¥ä½¿ç”¨çš„æ ¼å¼ 
    - å°†å¤„ç†åçš„æ•°æ®å­˜å‚¨åœ¨å¯¹åº”çš„æ•°æ®åº“ä¸­
2. æ£€ç´¢/ç´¢å¼•ï¼š
    - å°†ç”¨æˆ·çš„é—®é¢˜è¾“å…¥åˆ°æ£€ç´¢ç³»ç»Ÿä¸­ï¼Œä»æ•°æ®åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯
3. å¢å¼º
    - å¯¹æ£€ç´¢åˆ°çš„ä¿¡æ¯è¿›è¡Œå¤„ç†å’Œå¢å¼ºï¼Œä»¥ä¾¿ç”Ÿæˆæ¨¡å‹å¯ä»¥æ›´å¥½åœ°ç†è§£å’Œä½¿ç”¨
4. ç”Ÿæˆ
    - å°†å¢å¼ºåçš„ä¿¡æ¯è¾“å…¥åˆ°ç”Ÿæˆæ¨¡å‹ä¸­ï¼Œç”Ÿæˆæ¨¡å‹æ ¹æ®è¿™äº›ä¿¡æ¯ç”Ÿæˆç­”æ¡ˆ



# RAG æ¨¡å—

* ä¸€ä¸ªå‘é‡åŒ–æ¨¡å—ï¼Œç”¨æ¥å°†æ–‡æ¡£ç‰‡æ®µå‘é‡åŒ–
* ä¸€ä¸ªæ–‡æ¡£åŠ è½½å’Œåˆ‡åˆ†çš„æ¨¡å—ï¼Œç”¨æ¥åŠ è½½æ–‡æ¡£å¹¶åˆ‡åˆ†æˆæ–‡æ¡£ç‰‡æ®µ
* ä¸€ä¸ªæ•°æ®åº“æ¥å­˜æ”¾æ–‡æ¡£ç‰‡æ®µå’Œå¯¹åº”çš„å‘é‡è¡¨ç¤º
* ä¸€ä¸ªæ£€ç´¢æ¨¡å—ï¼Œç”¨æ¥æ ¹æ® Query(é—®é¢˜) æ£€ç´¢ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µ
* ä¸€ä¸ªå¤§æ¨¡å‹æ¨¡å—ï¼Œç”¨æ¥æ ¹æ®æ£€ç´¢å‡ºæ¥çš„æ–‡æ¡£å›ç­”ç”¨æˆ·çš„é—®é¢˜

## å‘é‡åŒ–

> Embedding

æ‰‹åŠ¨å®ç°ä¸€ä¸ªå‘é‡åŒ–çš„ç±»ï¼Œè¿™æ˜¯ RAG æ¶æ„çš„åŸºç¡€ã€‚å‘é‡åŒ–çš„ç±»ä¸»è¦ç”¨æ¥å°†æ–‡æ¡£ç‰‡æ®µå‘é‡åŒ–ï¼Œ
å°†ä¸€æ®µæ–‡æœ¬æ˜ å°„ä¸ºä¸€ä¸ªå‘é‡ã€‚è¿™é‡Œè®¾ç½®ä¸€ä¸ª `Embedding` åŸºç±»ï¼Œ
è¿™æ ·æˆ‘ä»¬åœ¨ç”¨å…¶ä»–çš„ Embedding æ¨¡å‹çš„æ—¶å€™ï¼Œåªéœ€è¦ç»§æ‰¿è¿™ä¸ªåŸºç±»ï¼Œ
ç„¶ååœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œä¿®æ”¹å³å¯ï¼Œæ–¹ä¾¿ä»£ç æ‰©å±•ã€‚

## æ–‡æ¡£åŠ è½½å’Œåˆ‡åˆ†

æ¥ä¸‹æ¥å®ç°ä¸€ä¸ªæ–‡æ¡£åŠ è½½ã€åˆ‡åˆ†çš„ç±»ï¼Œè¿™ä¸ªç±»ä¸»è¦æ˜¯ç”¨æ¥åŠ è½½æ–‡æ¡£å¹¶åˆ‡åˆ†æˆæ–‡æ¡£ç‰‡æ®µã€‚

é‚£ä¹ˆéœ€è¦åˆ‡åˆ†ä»€ä¹ˆæ–‡æ¡£å‘¢ï¼Ÿè¿™ä¸ªæ–‡æ¡£å¯ä»¥æ˜¯ä¸€ç¯‡æ–‡ç« ã€ä¸€æœ¬ä¹¦ã€ä¸€æ®µå¯¹è¯ã€ä¸€æ®µä»£ç ç­‰ç­‰ã€‚
è¿™ä¸ªæ–‡æ¡£çš„å†…å®¹å¯ä»¥æ˜¯ä»»ä½•çš„ï¼Œåªè¦æ˜¯æ–‡æœ¬å°±è¡Œï¼Œæ¯”å¦‚ï¼šPDF æ–‡ä»¶ã€MD æ–‡ä»¶ã€TXT æ–‡ä»¶ç­‰ã€‚

æŠŠæ–‡ä»¶å†…å®¹éƒ½è¯»å–ä¹‹åï¼Œè¿˜éœ€è¦åˆ‡åˆ†ã€‚æŒ‰ Token çš„é•¿åº¦æ¥åˆ‡åˆ†æ–‡æ¡£ã€‚
å¯ä»¥è®¾ç½®ä¸€ä¸ªæœ€å¤§çš„ Token é•¿åº¦ï¼Œç„¶åæ ¹æ®è¿™ä¸ªæœ€å¤§çš„ Token é•¿åº¦æ¥åˆ‡åˆ†æ–‡æ¡£ã€‚
è¿™æ ·åˆ‡åˆ†å‡ºæ¥çš„æ–‡æ¡£ç‰‡æ®µå°±æ˜¯ä¸€ä¸ªä¸€ä¸ªçš„å·®ä¸å¤šç›¸åŒé•¿åº¦çš„æ–‡æ¡£ç‰‡æ®µäº†ã€‚
ä¸è¿‡åœ¨åˆ‡åˆ†çš„æ—¶å€™è¦æ³¨æ„ï¼Œç‰‡æ®µä¸ç‰‡æ®µä¹‹é—´æœ€å¥½è¦æœ‰ä¸€äº›é‡å çš„å†…å®¹ï¼Œ
è¿™æ ·æ‰èƒ½ä¿è¯æ£€ç´¢çš„æ—¶å€™èƒ½å¤Ÿæ£€ç´¢åˆ°ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µã€‚
è¿˜æœ‰å°±æ˜¯åˆ‡åˆ†æ–‡æ¡£çš„æ—¶å€™æœ€å¥½ä»¥å¥å­ä¸ºå•ä½ï¼Œä¹Ÿå°±æ˜¯æŒ‰ `\n` è¿›è¡Œç²—åˆ‡åˆ†ï¼Œ
è¿™æ ·å¯ä»¥åŸºæœ¬ä¿è¯å¥å­å†…å®¹æ˜¯å®Œæ•´çš„ã€‚

## æ•°æ®åº“å’Œå‘é‡æ£€ç´¢

åšå¥½äº†æ–‡æ¡£åˆ‡åˆ†åï¼Œä¹Ÿåšå¥½äº† Embedding æ¨¡å‹çš„åŠ è½½ã€‚
æ¥ä¸‹æ¥å°±å¾—è®¾è®¡ä¸€ä¸ªå‘é‡æ•°æ®åº“ç”¨æ¥å­˜æ”¾æ–‡æ¡£ç‰‡æ®µå’Œå¯¹åº”çš„å‘é‡è¡¨ç¤ºäº†ã€‚

å¹¶ä¸”éœ€è¦è®¾è®¡ä¸€ä¸ªæ£€ç´¢æ¨¡å—ï¼Œç”¨æ¥æ ¹æ® Query ï¼ˆé—®é¢˜ï¼‰æ£€ç´¢ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µã€‚

ä¸€ä¸ªæ•°æ®åº“å¯¹äºæœ€å° RAG æ¶æ„æ¥è¯´ï¼Œéœ€è¦å®ç°å‡ ä¸ªåŠŸèƒ½:

* persistï¼šæ•°æ®åº“æŒä¹…åŒ–ï¼Œæœ¬åœ°ä¿å­˜
* load_vectorï¼šä»æœ¬åœ°åŠ è½½æ•°æ®åº“
* get_vectorï¼šè·å¾—æ–‡æ¡£çš„å‘é‡è¡¨ç¤º
* queryï¼šæ ¹æ®é—®é¢˜æ£€ç´¢ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µ

ä»¥ä¸Šå››ä¸ªæ¨¡å—å°±æ˜¯ä¸€ä¸ªæœ€å°çš„ RAG ç»“æ„æ•°æ®åº“éœ€è¦å®ç°çš„åŠŸèƒ½

query æ–¹æ³•å…·ä½“å®ç°ï¼š

1. é¦–å…ˆï¼Œå…ˆæŠŠç”¨æˆ·æå‡ºçš„é—®é¢˜å‘é‡åŒ–
2. ç„¶å, åœ¨æ•°æ®åº“ä¸­æ£€ç´¢ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µ
3. æœ€åè¿”å›æ£€ç´¢åˆ°çš„æ–‡æ¡£ç‰‡æ®µ

åœ¨å‘é‡æ£€ç´¢çš„æ—¶å€™ä»…ä½¿ç”¨ Numpy è¿›è¡ŒåŠ é€Ÿã€‚

## å¤§æ¨¡å‹æ¨¡å—

è¿™ä¸ªæ¨¡å—ä¸»è¦æ˜¯ç”¨æ¥æ ¹æ®æ£€ç´¢å‡ºæ¥çš„æ–‡æ¡£å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

# RAG ç»„ä»¶-LangChian

åœ¨å®é™…çš„ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œé€šå¸¸ä¼šé¢å¯¹æ¥è‡ªå¤šç§æ¸ é“çš„æ•°æ®ï¼Œå…¶ä¸­å¾ˆå¤§ä¸€éƒ¨åˆ†æ˜¯å¤æ‚çš„éæœºæ„åŒ–æ•°æ®ï¼Œ
å¤„ç†è¿™äº›æ•°æ®ï¼Œç‰¹åˆ«æ˜¯æå–å’Œé¢„å¤„ç†ï¼Œå¾€å¾€æ˜¯è€—è´¹ç²¾åŠ›çš„ä»»åŠ¡ä¹‹ä¸€ã€‚
å› æ­¤ LangChain æä¾›äº†ä¸“é—¨çš„æ–‡æ¡£åŠ è½½å’Œåˆ†å‰²æ¨¡å—ã€‚RAG æŠ€æœ¯çš„æ¯ä¸ªé˜¶æ®µéƒ½åœ¨ LangChain ä¸­å¾—åˆ°å®Œæ•´çš„å®ç°ã€‚

## LangChain ä¸­çš„ RAG ç»„ä»¶

TODO

## LLM æ¥å…¥ LangChain

LangChain ä¸ºåŸºäº LLM å¼€å‘è‡ªå®šä¹‰åº”ç”¨æä¾›äº†é«˜æ•ˆçš„å¼€å‘æ¡†æ¶ï¼Œä¾¿äºå¼€å‘è€…è¿…é€Ÿåœ°æ¿€å‘ LLM çš„å¼ºå¤§èƒ½åŠ›ï¼Œ
æ­å»º LLM åº”ç”¨ã€‚LangChain ä¹ŸåŒæ ·æ”¯æŒå¤šç§å¤§æ¨¡å‹ï¼Œå†…ç½®äº† OpenAIã€LLAMA ç­‰å¤§æ¨¡å‹çš„è°ƒç”¨æ¥å£ã€‚
ä½†æ˜¯ï¼ŒLangChain å¹¶æ²¡æœ‰å†…ç½®æ‰€æœ‰å¤§æ¨¡å‹ï¼Œå®ƒé€šè¿‡å…è®¸ç”¨æˆ·è‡ªå®šä¹‰ LLM ç±»å‹ï¼Œæ¥æä¾›å¼ºå¤§çš„å¯æ‰©å±•æ€§ã€‚

### åŸºäº LangChain è°ƒç”¨ ChatGPT

LangChain æä¾›äº†å¯¹äºå¤šæ•°å¤§æ¨¡å‹çš„å°è£…ï¼Œ
åŸºäº LangChain çš„æ¥å£å¯ä»¥ä¾¿æ·åœ°è°ƒç”¨ ChatGPT å¹¶å°†å…¶é›†åˆåœ¨ä»¥ LangChain ä¸ºåŸºç¡€æ¡†æ¶æ­å»ºçš„ä¸ªäººåº”ç”¨ä¸­ã€‚

æ³¨ï¼šåŸºäº LangChain æ¥å£è°ƒç”¨ ChatGPT åŒæ ·éœ€è¦é…ç½®ä¸ªäººå¯†é’¥ã€‚

#### Model

ä» `langchain.chat_models` å¯¼å…¥ OpenAI çš„å¯¹è¯æ¨¡å‹ `ChatOpenAI`ã€‚é™¤äº† OpenAI ä»¥å¤–ï¼Œ
`langchain.chat_models` è¿˜é›†æˆäº†å…¶ä»–å¯¹è¯æ¨¡å‹ã€‚

```python
import os
import openai
from dotenv import load_dotenv, find_dotenv
from langchain.openai import ChatOpenAI

# è¯»å–æœ¬åœ°çš„ç¯å¢ƒå˜é‡
_ = load_dotenv(find_dotenv())

# è·å–ç¯å¢ƒå˜é‡ OPENAI_API_KEY
openai_api_key = os.environ("OPENAI_API_KEY")

# OpenAI API å¯†é’¥åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½®
llm = ChatOpenAI(temperature = 0.0)
# æ‰‹åŠ¨æŒ‡å®š API å¯†é’¥
llm = ChatOpenAI(temperature = 0.0, openai_api_key = "YOUR_API_KEY")

output = llm.invoke("è¯·ä½ è‡ªæˆ‘ä»‹ç»ä»¥ä¸‹è‡ªå·±ï¼")
output
```

å¯ä»¥çœ‹åˆ°ï¼Œé»˜è®¤è°ƒç”¨çš„æ˜¯ ChatGPT-3.5 æ¨¡å‹ã€‚å¦å¤–ï¼Œå‡ ç§å¸¸ç”¨çš„è¶…å‚æ•°è®¾ç½®åŒ…æ‹¬ï¼š

* `model_name`ï¼šæ‰€è¦ä½¿ç”¨çš„æ¨¡å‹ï¼Œé»˜è®¤ä¸º `'gpt-3.5-turbo'`ï¼Œå‚æ•°è®¾ç½®ä¸ OpenAI åŸç”Ÿæ¥å£å‚æ•°è®¾ç½®ä¸€è‡´ã€‚
* `temperature`ï¼šæ¸©åº¦ç³»æ•°ï¼Œå–å€¼åŒåŸç”Ÿæ¥å£ã€‚
* `openai_api_key`ï¼šOpenAI API keyï¼Œå¦‚æœä¸ä½¿ç”¨ç¯å¢ƒå˜é‡è®¾ç½® API Keyï¼Œä¹Ÿå¯ä»¥åœ¨å®ä¾‹åŒ–æ—¶è®¾ç½®ã€‚
* `openai_proxy`ï¼šè®¾ç½®ä»£ç†ï¼Œå¦‚æœä¸ä½¿ç”¨ç¯å¢ƒå˜é‡è®¾ç½®ä»£ç†ï¼Œä¹Ÿå¯ä»¥åœ¨å®ä¾‹åŒ–æ—¶è®¾ç½®ã€‚
* `streaming`ï¼šæ˜¯å¦ä½¿ç”¨æµå¼ä¼ è¾“ï¼Œå³é€å­—è¾“å‡ºæ¨¡å‹å›ç­”ï¼Œé»˜è®¤ä¸º `False`ï¼Œæ­¤å¤„ä¸èµ˜è¿°ã€‚
* `max_tokens`ï¼šæ¨¡å‹è¾“å‡ºçš„æœ€å¤§ token æ•°ï¼Œæ„ä¹‰åŠå–å€¼åŒä¸Šã€‚

#### Prompt

åœ¨å¼€å‘å¤§æ¨¡å‹åº”ç”¨æ—¶ï¼Œå¤§å¤šæ•°æƒ…å†µä¸‹ä¸ä¼šç›´æ¥å°†ç”¨æˆ·çš„è¾“å…¥ç›´æ¥ä¼ é€’ç»™ LLMã€‚
é€šå¸¸ï¼Œä»–ä»¬ä¼šå°†ç”¨æˆ·è¾“å…¥æ·»åŠ åˆ°ä¸€ä¸ªè¾ƒå¤§çš„æ–‡æœ¬ä¸­ï¼Œç§°ä¸ºæç¤ºæ¨¡æ¿(Prompt Template)ï¼Œ
è¯¥æ–‡æœ¬æä¾›æœ‰å…³å½“å‰ç‰¹å®šä»»åŠ¡çš„é™„åŠ ä¸Šä¸‹æ–‡ã€‚

`PromptTemplates` æ­£æ˜¯å¸®åŠ©è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå®ƒä»¬æ†ç»‘äº†ä»ç”¨æˆ·è¾“å…¥åˆ°å®Œå…¨æ ¼å¼åŒ–çš„æç¤ºçš„æ‰€æœ‰é€»è¾‘ã€‚
è¿™å¯ä»¥éå¸¸ç®€å•åœ°å¼€å§‹ã€‚ä¾‹å¦‚ï¼Œç”Ÿæˆä¸Šè¿°å­—ç¬¦ä¸²çš„æç¤ºå°±æ˜¯ã€‚

èŠå¤©æ¨¡å‹çš„æ¥å£æ˜¯åŸºäºæ¶ˆæ¯ï¼ˆmessageï¼‰ï¼Œè€Œä¸æ˜¯åŸå§‹çš„æ–‡æœ¬ã€‚
`PromptTemplates` ä¹Ÿå¯ä»¥ç”¨äºäº§ç”Ÿæ¶ˆæ¯åˆ—è¡¨ï¼Œåœ¨è¿™ç§æ ·ä¾‹ä¸­ï¼Œ
prompt ä¸ä»…åŒ…å«äº†è¾“å…¥å†…å®¹ä¿¡æ¯ï¼Œä¹ŸåŒ…å«äº†æ¯æ¡ message çš„ä¿¡æ¯(è§’è‰²ã€åœ¨åˆ—è¡¨ä¸­çš„ä½ç½®ç­‰)ã€‚
é€šå¸¸æƒ…å†µä¸‹ï¼Œä¸€ä¸ª `ChatPromptTemplate` æ˜¯ä¸€ä¸ª `ChatMessageTemplate` çš„åˆ—è¡¨ã€‚
æ¯ä¸ª `ChatMessageTemplate` åŒ…å«æ ¼å¼åŒ–è¯¥èŠå¤©æ¶ˆæ¯çš„è¯´æ˜ï¼ˆå…¶è§’è‰²ä»¥åŠå†…å®¹ï¼‰ã€‚

```python
from langchain.prompts.chat import ChatPromptTemplate

template = "ä½ æ˜¯ä¸€ä¸ªç¿»è¯‘åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©æˆ‘å°† {input_language} ç¿»è¯‘æˆ {output_language}"
human_template = "{text}"
text = "æˆ‘å¸¦ç€æ¯”èº«ä½“é‡çš„è¡Œæï¼Œ\
æ¸¸å…¥å°¼ç½—æ²³åº•ï¼Œ\
ç»è¿‡å‡ é“é—ªç”µ çœ‹åˆ°ä¸€å †å…‰åœˆï¼Œ\
ä¸ç¡®å®šæ˜¯ä¸æ˜¯è¿™é‡Œã€‚\"

chat_prompt = ChatPromptTemplate([
     ("system", template),
     ("human", human_template),
])

message = chat_prompt.format_messages(
     input_language = "ä¸­æ–‡", 
     output_language = "è‹±æ–‡", 
     text = text
)
print(message)

output = llm.invoke(message)
print(output)
```

#### Output parser

`OutputParsers` å°†è¯­è¨€æ¨¡å‹çš„åŸå§‹è¾“å‡ºè½¬æ¢ä¸ºå¯ä»¥åœ¨ä¸‹æ¸¸ä½¿ç”¨çš„æ ¼å¼ã€‚
`OutputParser` æœ‰å‡ ç§ä¸»è¦ç±»å‹ï¼ŒåŒ…æ‹¬ï¼š

* å°† LLM æ–‡æœ¬è½¬æ¢ä¸ºç»“æ„åŒ–ä¿¡æ¯(ä¾‹å¦‚ JSON)
* å°† `ChatMessage` è½¬æ¢ä¸ºå­—ç¬¦ä¸²
* å°†é™¤æ¶ˆæ¯ä¹‹å¤–çš„è°ƒç”¨è¿”å›çš„é¢å¤–ä¿¡æ¯ï¼ˆå¦‚ OpenAI å‡½æ•°è°ƒç”¨ï¼‰è½¬æ¢ä¸ºå­—ç¬¦ä¸²

æœ€åï¼Œæˆ‘ä»¬å°†æ¨¡å‹è¾“å‡ºä¼ é€’ç»™ `output_parser`ï¼Œå®ƒæ˜¯ä¸€ä¸ª `BaseOutputParser`ï¼Œ
è¿™æ„å‘³ç€å®ƒæ¥å—å­—ç¬¦ä¸²æˆ– `BaseMessage` ä½œä¸ºè¾“å…¥ã€‚
`StrOutputParser` ç‰¹åˆ«ç®€å•åœ°å°†ä»»ä½•è¾“å…¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²ã€‚

```python
from langchain_core.output_parsers import StrOutputParser

output_parser = StrOutputParser()
output_parser.invoke(output)
```

ä»ä¸Šé¢ç»“æœå¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬é€šè¿‡è¾“å‡ºè§£æå™¨æˆåŠŸå°† ChatMessage ç±»å‹çš„è¾“å‡ºè§£æä¸ºäº†å­—ç¬¦ä¸²ã€‚

#### å®Œæ•´çš„æµç¨‹

ç°åœ¨å¯ä»¥å°†æ‰€æœ‰è¿™äº›ç»„åˆæˆä¸€æ¡é“¾ï¼Œè¯¥é“¾å°†è·å–è¾“å…¥å˜é‡ï¼Œå°†è¿™äº›å˜é‡ä¼ é€’ç»™æç¤ºæ¨¡æ¿ä»¥åˆ›å»ºæç¤ºï¼Œ
å°†æç¤ºä¼ é€’ç»™è¯­è¨€æ¨¡å‹ï¼Œç„¶åé€šè¿‡ï¼ˆå¯é€‰ï¼‰è¾“å‡ºè§£æå™¨ä¼ é€’è¾“å‡ºã€‚ä¸‹é¢ä½¿ç”¨ LCEL è¿™ç§è¯­æ³•å»å¿«é€Ÿå®ç°ä¸€æ¡é“¾ï¼ˆchainï¼‰ã€‚

```python
chain = chat_prompt | llm | output_parser
chain.invoke({
     "input_language": "ä¸­æ–‡",
     "output_language": "è‹±æ–‡",
     "text": text,
})

text = "I carried luggage heavier than my body and dived into the bottom of the Nile River. After passing through several flashes of lightning, I saw a pile of halos, not sure if this is the place."
chain.invoke({
     "input_language": "è‹±æ–‡", 
     "output_language": "ä¸­æ–‡",
     "text": text
})
```

### ä½¿ç”¨ LangChain è°ƒç”¨æ–‡å¿ƒä¸€è¨€

é€šè¿‡ LangChain æ¡†æ¶æ¥è°ƒç”¨ç™¾åº¦æ–‡å¿ƒå¤§æ¨¡å‹ï¼Œä»¥å°†æ–‡å¿ƒæ¨¡å‹æ¥å…¥åˆ°åº”ç”¨æ¡†æ¶ä¸­ã€‚

#### è‡ªå®šä¹‰ LLM æ¥å…¥ langchain



#### åœ¨ langchain ç›´æ¥è°ƒç”¨æ–‡å¿ƒä¸€è¨€

### ä½¿ç”¨ LangChain è°ƒç”¨è®¯é£æ˜Ÿç«



### ä½¿ç”¨ LangChain è°ƒç”¨æ™ºè°± GLM

#### è‡ªå®šä¹‰ chatglm

ç”±äº LangChain ä¸­æä¾›çš„ ChatGLM å·²ä¸å¯ç”¨ï¼Œå› æ­¤éœ€è¦è‡ªå®šä¹‰ä¸€ä¸ª LLMã€‚

```python
#!/usr/bin/env python
# -*- encoding: utf-8 -*-

import os
from typing import Any, List, Mapping, Optional, Dict
from langchain_core.callbacks.manager import CallbackManagerForLLMRun
from langchain_core.language_models.llms import LLM
from zhipuai import ZhipuAI

# ç»§æ‰¿è‡ª langchain.llms.base.LLM
class ZhipuAILLM(LLM):
    # é»˜è®¤é€‰ç”¨ glm-4
    model: str = "glm-4"
    # æ¸©åº¦ç³»æ•°
    temperature: float = 0.1
    # API_Key
    api_key: str = None
    
    def _call(self, prompt : str, stop: Optional[List[str]] = None,
                run_manager: Optional[CallbackManagerForLLMRun] = None,
                **kwargs: Any):
        client = ZhipuAI(
            api_key = self.api_key
        )

        def gen_glm_params(prompt):
            '''
            æ„é€  GLM æ¨¡å‹è¯·æ±‚å‚æ•° messages

            è¯·æ±‚å‚æ•°ï¼š
                prompt: å¯¹åº”çš„ç”¨æˆ·æç¤ºè¯
            '''
            messages = [{"role": "user", "content": prompt}]
            return messages
        
        messages = gen_glm_params(prompt)
        response = client.chat.completions.create(
            model = self.model,
            messages = messages,
            temperature = self.temperature
        )

        if len(response.choices) > 0:
            return response.choices[0].message.content
        return "generate answer error"


    # é¦–å…ˆå®šä¹‰ä¸€ä¸ªè¿”å›é»˜è®¤å‚æ•°çš„æ–¹æ³•
    @property
    def _default_params(self) -> Dict[str, Any]:
        """è·å–è°ƒç”¨APIçš„é»˜è®¤å‚æ•°ã€‚"""
        normal_params = {
            "temperature": self.temperature,
            }
        # print(type(self.model_kwargs))
        return {**normal_params}

    @property
    def _llm_type(self) -> str:
        return "Zhipu"

    @property
    def _identifying_params(self) -> Mapping[str, Any]:
        """Get the identifying parameters."""
        return {**{"model": self.model}, **self._default_params}
```

#### è‡ªå®šä¹‰ chatglm æ¥å…¥ LangChain

```python
import os
from zhipuai_llm import ZhipuAILLM
from dotenv import find_dotenv, load_dotenv

# è¯»å–æœ¬åœ°/é¡¹ç›®çš„ç¯å¢ƒå˜é‡
_ = load_dotenv(find_dotenv())

# è·å–ç¯å¢ƒå˜é‡ API_KEY
api_key = os.environ["ZHIPUAI_API_KEY"]

zhipuai_model = ZhipuAILLM(model = "glm-4", temperature = 0.1, api_key = api_key)  # model="glm-4-0520"
zhipuai_model("ä½ å¥½ï¼Œè¯·è‡ªæˆ‘ä»‹ç»ä»¥ä¸‹ï¼")
```

## åŸºäº LangChain æ„å»ºæ£€ç´¢é—®ç­”é“¾

åœ¨[è¿™é‡Œ]()ä»‹ç»äº†å¦‚ä½•æ ¹æ®è‡ªå·±çš„æœ¬åœ°çŸ¥è¯†æ–‡æ¡£ï¼Œæ­å»ºä¸€ä¸ªå‘é‡çŸ¥è¯†åº“ã€‚
ä½¿ç”¨æ­å»ºå¥½çš„å‘é‡æ•°æ®åº“ï¼Œå¯¹ query æŸ¥è¯¢é—®é¢˜è¿›è¡Œå¬å›ï¼Œ
å¹¶å°†å¬å›ç»“æœå’Œ query ç»“åˆèµ·æ¥æ„å»º promptï¼Œè¾“å…¥åˆ°å¤§æ¨¡å‹ä¸­è¿›è¡Œé—®ç­”ã€‚

### åŠ è½½æ•°æ®åº“å‘é‡



### åˆ›å»ºä¸€ä¸ª LLM


### æ„å»ºæ£€ç´¢é—®ç­”é“¾



### æ£€ç´¢é—®ç­”é“¾æ•ˆæœæµ‹è¯•


### æ·»åŠ å†å²å¯¹è¯çš„è®°å¿†åŠŸèƒ½


## åŸºäº Streamlit éƒ¨ç½²çŸ¥è¯†åº“åŠ©æ‰‹

å½“å¯¹çŸ¥è¯†åº“å’Œ LLM å·²ç»æœ‰äº†åŸºæœ¬çš„ç†è§£ï¼Œç°åœ¨æ˜¯å°†å®ƒä»¬å·§å¦™åœ°èåˆå¹¶æ‰“é€ æˆä¸€ä¸ªå¯Œæœ‰è§†è§‰æ•ˆæœçš„ç•Œé¢çš„æ—¶å€™äº†ã€‚
è¿™æ ·çš„ç•Œé¢ä¸ä»…å¯¹æ“ä½œæ›´åŠ ä¾¿æ·ï¼Œè¿˜èƒ½ä¾¿äºä¸ä»–äººåˆ†äº«ã€‚

> Streamlit æ˜¯ä¸€ç§å¿«é€Ÿä¾¿æ·çš„æ–¹æ³•ï¼Œå¯ä»¥ç›´æ¥åœ¨ Python ä¸­é€šè¿‡å‹å¥½çš„ Web ç•Œé¢æ¼”ç¤ºæœºå™¨å­¦ä¹ æ¨¡å‹ã€‚
> åœ¨æ„å»ºäº†æœºå™¨å­¦ä¹ æ¨¡å‹åï¼Œå¦‚æœæƒ³æ„å»ºä¸€ä¸ª demo ç»™å…¶ä»–äººçœ‹ï¼Œä¹Ÿè®¸æ˜¯ä¸ºäº†è·å¾—åé¦ˆå¹¶æ¨åŠ¨ç³»ç»Ÿçš„æ”¹è¿›ï¼Œ
> æˆ–è€…åªæ˜¯å› ä¸ºè§‰å¾—è¿™ä¸ªç³»ç»Ÿå¾ˆé…·ï¼Œæ‰€ä»¥æƒ³æ¼”ç¤ºä¸€ä¸‹ï¼šStreamlit å¯ä»¥é€šè¿‡ Python æ¥å£ç¨‹åºå¿«é€Ÿå®ç°è¿™ä¸€ç›®æ ‡ï¼Œ
> è€Œæ— éœ€ç¼–å†™ä»»ä½•å‰ç«¯ã€ç½‘é¡µæˆ– JavaScript ä»£ç ã€‚

### æ„å»ºåº”ç”¨ç¨‹åº

```python
# streamlit_app.py
import streamlit as st
from langchain_openai import ChatOpenAI


def generate_response(input_text, openai_api_key):
     """
     å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œä½¿ç”¨ç”¨æˆ·å¯†é’¥å¯¹ OpenAI API è¿›è¡Œèº«ä»½éªŒè¯ã€å‘é€æç¤ºå¹¶è·å– AI ç”Ÿæˆçš„å“åº”ã€‚
     è¯¥å‡½æ•°æ¥å—ç”¨æˆ·çš„æç¤ºä½œä¸ºå‚æ•°ï¼Œå¹¶ä½¿ç”¨ st.info æ¥åœ¨è“è‰²æ¡†ä¸­æ˜¾ç¤º AI ç”Ÿæˆçš„å“åº”ã€‚
     """
     llm = ChatOpenAI(temperature = 0.7, openai_api_key = openai_api_key)
     output = llm.invoke(input_text)
     output_parser = StrOutputParser()
     output = output_parser.invoke(output)
     # st.info(output)
     return output


# Streamlit åº”ç”¨ç¨‹åºç•Œé¢
def main():
     # åˆ›å»ºåº”ç”¨ç¨‹åºçš„æ ‡é¢˜
     st.title("ğŸ¦œğŸ”— åŠ¨æ‰‹å­¦å¤§æ¨¡å‹åº”ç”¨å¼€å‘")

     # æ·»åŠ ä¸€ä¸ªæ–‡æœ¬è¾“å…¥æ¡†ï¼Œä¾›ç”¨æˆ·è¾“å…¥å…¶ OpenAI API å¯†é’¥
     openai_api_key = st.sidebar.text_input("OpenAI API Key", type = "password")

     # ä½¿ç”¨ st.form() åˆ›å»ºä¸€ä¸ªæ–‡æœ¬æ¡† st.text_area() ä¾›ç”¨æˆ·è¾“å…¥ã€‚
     # å½“ç”¨æˆ·ç‚¹å‡» Submit æ—¶ï¼Œgenerate_response å°†ä½¿ç”¨ç”¨æˆ·çš„è¾“å…¥ä½œä¸ºå‚æ•°æ¥è°ƒç”¨è¯¥å‡½æ•°
     with st.form("my_form"):
          text = st.text_area(
               "Enter text:", 
               "What are the three key pieces of advice for learning how to code?"
          )
          
          submitted = st.form_submit_button("Submit")

          if not openai_api_key.startswith("sk-"):
               st.warning("Please enter your OpenAI API key!", icon = "")
          if submitted and openai_api_key.startswith("sk-"):
               generate_response(text, openai_api_key)
  
     # é€šè¿‡ä½¿ç”¨ st.session_state æ¥å­˜å‚¨å¯¹è¯å†å²ï¼Œ
     # å¯ä»¥åœ¨ç”¨æˆ·ä¸åº”ç”¨ç¨‹åºäº¤äº’æ—¶ä¿ç•™æ•´ä¸ªå¯¹è¯çš„ä¸Šä¸‹æ–‡ï¼Œ
     # ç”¨äºè·Ÿè¸ªå¯¹è¯å†å²
     if "messages" not in st.session_state:
          st.session_state.messages = []
     
     messages = st.container(height = 300)
     if prompt := st.chat_input("Say something"):
          # å°†ç”¨æˆ·è¾“å…¥æ·»åŠ åˆ°å¯¹è¯å†å²ä¸­
          st.session_state.messages.appen({
               "role": "user",
               "text": prompt,
          })
          
          # è°ƒç”¨ respond å‡½æ•°è·å–å›ç­”
          answer = generate_response(prompt, openai_api_key)
          # æ£€æŸ¥å›ç­”æ˜¯å¦ä¸º None
          if answer is not None:
               # å°† LLM çš„å›ç­”æ·»åŠ åˆ°å¯¹è¯å†å²ä¸­
               st.session_state.messages.append({
                    "role": "assistant",
                    "text": answer,
               })
          
          # æ˜¾ç¤ºæ•´ä¸ªå¯¹è¯å†å²
          for message in st.session_state.messages:
               if message["role"] == "user":
                    messages.chat_message("user").write(message["text"])
               else:
                    messages.chat_message("assistant").write(message["text"])
```

```bash
$ streamlit run streamlit_app.py
```

### æ·»åŠ æ£€ç´¢å›ç­”

æ„å»ºæ£€ç´¢é—®ç­”é“¾ä»£ç ï¼š

* `get_vectordb` å‡½æ•°è¿”å›æŒä¹…åŒ–åçš„å‘é‡çŸ¥è¯†åº“
* `get_chat_qa_chain` å‡½æ•°è¿”å›è°ƒç”¨å¸¦æœ‰å†å²è®°å½•çš„æ£€ç´¢é—®ç­”é“¾åçš„ç»“æœ
* `get_qa_chain` å‡½æ•°è¿”å›è°ƒç”¨ä¸å¸¦æœ‰å†å²è®°å½•çš„æ£€ç´¢é—®ç­”é“¾åçš„ç»“æœ

```python
def get_vectordb():
     """
     å‡½æ•°è¿”å›æŒä¹…åŒ–åçš„å‘é‡çŸ¥è¯†åº“
     """
     # å®šä¹‰ Embeddings
     embedding = ZhipuAIEmbeddings()
     # å‘é‡æ•°æ®åº“æŒä¹…åŒ–è·¯å¾„
     persist_directory = "data_base/vector_db/chroma"
     # åŠ è½½æ•°æ®åº“
     vectordb = Chroma(
          persist_directory = persist_directory,
          embedding_function = embedding,
     )
     return vectordb

def get_chat_qa_chain(question: str, openai_api_key: str):
     """
     å¸¦æœ‰å†å²è®°å½•çš„é—®ç­”é“¾
     """
     vectordb = get_vectordb()
     llm = ChatOpenAI(
          model_name = "gpt-3.5-turbo", 
          temperature = 0, 
          openai_api_key = openai_api_key
     )
     memory = ConversationBufferMemory(
          memory_key = "chat_history",  # ä¸ prompt çš„è¾“å…¥å˜é‡ä¿æŒä¸€è‡´
          return_messages = True,  # å°†æ¶ˆæ¯åˆ—è¡¨çš„å½¢å¼è¿”å›èŠå¤©è®°å½•ï¼Œè€Œä¸æ˜¯å•ä¸ªå­—ç¬¦ä¸²
     )
     retriever = vectordb.as_retriever()
     qa = ConversationBufferMemory.from_llm(
          llm, 
          retriever = retriever,
          memory = memory,
     )
     result = qa({
          "question": question
     })
     
     return result["answer"]


def get_qa_chain(question: str, openai_api_key: str):
     """
     ä¸å¸¦å†å²è®°å½•çš„é—®ç­”é“¾
     """
     vectordb = get_vectordb()
     llm = ChatOpenAI(
          model = "gpt-3.5-turbo",
          temperature = 0,
          opanai_api_key = oepnai_api_key,
     )
     template = """"ä½¿ç”¨ä»¥ä¸‹ä¸Šä¸‹æ–‡æ¥å›ç­”æœ€åçš„é—®é¢˜ã€‚å¦‚æœä½ ä¸çŸ¥é“ç­”æ¡ˆï¼Œå°±è¯´ä½ ä¸çŸ¥é“ï¼Œä¸è¦è¯•å›¾ç¼–é€ ç­”
        æ¡ˆã€‚æœ€å¤šä½¿ç”¨ä¸‰å¥è¯ã€‚å°½é‡ä½¿ç­”æ¡ˆç®€æ˜æ‰¼è¦ã€‚æ€»æ˜¯åœ¨å›ç­”çš„æœ€åè¯´â€œè°¢è°¢ä½ çš„æé—®ï¼â€ã€‚
        {context}
        é—®é¢˜: {question}
        """
     QA_CHAIN_PROMPT = PromptTemplate(
          input_variables = ["context", "question"],
          template = template,
     )
     qa_chain = RetrievalQA.from_chain_type(
          llm,
          retriever = vectordb.as_retriever(),
          return_source_documents = True,
          chain_type_kwargs = {"prompt": QA_CHAIN_PROMPT}
     )
     result = qa_chain({"query": question})

     return result["result"]
```

ç„¶åï¼Œæ·»åŠ ä¸€ä¸ªå•é€‰æŒ‰é’®éƒ¨ä»¶ `st.radio`ï¼Œé€‰æ‹©è¿›è¡Œå›ç­”æ¨¡å¼ï¼š

* `None` ä¸ä½¿ç”¨æ£€ç´¢é—®ç­”çš„æ™®é€šæ¨¡å¼
* `qa_chain` ä¸å¸¦å†å²è®°å½•çš„æ£€ç´¢é—®ç­”æ¨¡å¼
* `chat_qa_chain` å¸¦å†å²è®°å½•çš„æ£€ç´¢é—®ç­”æ¨¡å¼

```python
selected_method = st.radio(
     "ä½ æƒ³é€‰æ‹©å“ªç§æ¨¡å¼è¿›è¡Œå¯¹è¯ï¼Ÿ",
     [
          "None", 
          "qa_chain", 
          "chat_qa_chain"
     ],
     caption = [
          "ä¸ä½¿ç”¨æ£€ç´¢å›ç­”çš„æ™®é€šæ¨¡å¼", 
          "ä¸å¸¦å†å²è®°å½•çš„æ£€ç´¢é—®ç­”æ¨¡å¼", 
          "å¸¦å†å²è®°å½•çš„æ£€ç´¢é—®ç­”æ¨¡å¼"
     ]
)
```

æœ€åï¼Œè¿›å…¥é¡µé¢ï¼Œé¦–å…ˆå…ˆè¾“å…¥ `OPEN_API_KEY`ï¼ˆé»˜è®¤ï¼‰ï¼Œ
ç„¶åç‚¹å‡»å•é€‰æŒ‰é’®é€‰æ‹©è¿›è¡Œé—®ç­”çš„æ¨¡å¼ï¼Œæœ€ååœ¨è¾“å…¥æ¡†è¾“å…¥ä½ çš„é—®é¢˜ï¼ŒæŒ‰ä¸‹å›è½¦å³å¯ã€‚

å®Œæ•´ä»£ç ï¼š

```python
# python libraries
import os
import sys
ROOT = os.getcwd()
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))

import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain.vectorstores.chroma import Chroma
from langchain.memory import ConversationBufferMemory
from langchain_core.output_parsers import StrOutputParser

from embedding_api.zhipuai_embedding import ZhipuAIEmbeddings
from dotenv import load_dotenv, find_dotenv

# å°†çˆ¶ç›®å½•æ”¾å…¥ç³»ç»Ÿè·¯å¾„ä¸­
sys.path.append("../knowledge_lib") 
# è¯»å–æœ¬åœ° .env æ–‡ä»¶
_ = load_dotenv(find_dotenv())
# è½½å…¥ ***_API_KEY
os.environ["OPENAI_API_BASE"] = "https://api.chatgptid.net/v1"
zhipuai_api_key = os.environ["ZHIPUAI_API_KEY"]
# global variable
LOGGING_LABEL = __file__.split('/')[-1][:-3]


def generate_response(input_text, openai_api_key):
     """
     å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œä½¿ç”¨ç”¨æˆ·å¯†é’¥å¯¹ OpenAI API è¿›è¡Œèº«ä»½éªŒè¯ã€å‘é€æç¤ºå¹¶è·å– AI ç”Ÿæˆçš„å“åº”ã€‚
     è¯¥å‡½æ•°æ¥å—ç”¨æˆ·çš„æç¤ºä½œä¸ºå‚æ•°ï¼Œå¹¶ä½¿ç”¨ st.info æ¥åœ¨è“è‰²æ¡†ä¸­æ˜¾ç¤º AI ç”Ÿæˆçš„å“åº”ã€‚
     """
     llm = ChatOpenAI(temperature = 0.7, openai_api_key = openai_api_key)
     output = llm.invoke(input_text)
     output_parser = StrOutputParser()
     output = output_parser.invoke(output)
     # st.info(output)
     return output


def get_vectordb():
     """
     å‡½æ•°è¿”å›æŒä¹…åŒ–åçš„å‘é‡çŸ¥è¯†åº“
     """
     # å®šä¹‰ Embeddings
     embedding = ZhipuAIEmbeddings()
     # å‘é‡æ•°æ®åº“æŒä¹…åŒ–è·¯å¾„
     persist_directory = "data_base/vector_db/chroma"
     # åŠ è½½æ•°æ®åº“
     vectordb = Chroma(
          persist_directory = persist_directory,
          embedding_function = embedding,
     )

     return vectordb


def get_chat_qa_chain(question: str, openai_api_key: str):
     """
     å¸¦æœ‰å†å²è®°å½•çš„é—®ç­”é“¾
     """
     vectordb = get_vectordb()
     llm = ChatOpenAI(
          model_name = "gpt-3.5-turbo", 
          temperature = 0, 
          openai_api_key = openai_api_key
     )
     memory = ConversationBufferMemory(
          memory_key = "chat_history",  # ä¸ prompt çš„è¾“å…¥å˜é‡ä¿æŒä¸€è‡´
          return_messages = True,  # å°†æ¶ˆæ¯åˆ—è¡¨çš„å½¢å¼è¿”å›èŠå¤©è®°å½•ï¼Œè€Œä¸æ˜¯å•ä¸ªå­—ç¬¦ä¸²
     )
     retriever = vectordb.as_retriever()
     qa = ConversationBufferMemory.from_llm(
          llm, 
          retriever = retriever,
          memory = memory,
     )
     result = qa({
          "question": question
     })
     
     return result["answer"]


def get_qa_chain(question: str, openai_api_key: str):
     """
     ä¸å¸¦å†å²è®°å½•çš„é—®ç­”é“¾
     """
     vectordb = get_vectordb()
     llm = ChatOpenAI(
          model = "gpt-3.5-turbo",
          temperature = 0,
          opanai_api_key = openai_api_key,
     )
     template = """"ä½¿ç”¨ä»¥ä¸‹ä¸Šä¸‹æ–‡æ¥å›ç­”æœ€åçš„é—®é¢˜ã€‚å¦‚æœä½ ä¸çŸ¥é“ç­”æ¡ˆï¼Œå°±è¯´ä½ ä¸çŸ¥é“ï¼Œä¸è¦è¯•å›¾ç¼–é€ ç­”
        æ¡ˆã€‚æœ€å¤šä½¿ç”¨ä¸‰å¥è¯ã€‚å°½é‡ä½¿ç­”æ¡ˆç®€æ˜æ‰¼è¦ã€‚æ€»æ˜¯åœ¨å›ç­”çš„æœ€åè¯´â€œè°¢è°¢ä½ çš„æé—®ï¼â€ã€‚
        {context}
        é—®é¢˜: {question}
        """
     QA_CHAIN_PROMPT = PromptTemplate(
          input_variables = ["context", "question"],
          template = template,
     )
     qa_chain = RetrievalQA.from_chain_type(
          llm,
          retriever = vectordb.as_retriever(),
          return_source_documents = True,
          chain_type_kwargs = {"prompt": QA_CHAIN_PROMPT}
     )
     result = qa_chain({"query": question})

     return result["result"]




# Streamlit åº”ç”¨ç¨‹åºç•Œé¢
def main():
     # åˆ›å»ºåº”ç”¨ç¨‹åºçš„æ ‡é¢˜
     st.title("ğŸ¦œğŸ”— åŠ¨æ‰‹å­¦å¤§æ¨¡å‹åº”ç”¨å¼€å‘")
     # æ·»åŠ ä¸€ä¸ªæ–‡æœ¬è¾“å…¥æ¡†ï¼Œä¾›ç”¨æˆ·è¾“å…¥å…¶ OpenAI API å¯†é’¥
     openai_api_key = st.sidebar.text_input("OpenAI API Key", type = "password")
     # æ·»åŠ ä¸€ä¸ªé€‰æ‹©æŒ‰é’®æ¥é€‰æ‹©ä¸åŒçš„æ¨¡å‹
     # selected_method = st.sidebar.selectbox(
     #      "é€‰æ‹©æ¨¡å¼", 
     #      [
     #           "None", 
     #           "qa_chain", 
     #           "chat_qa_chain"
     #      ]
     # )
     selected_method = st.radio(
          "ä½ æƒ³é€‰æ‹©å“ªç§æ¨¡å¼è¿›è¡Œå¯¹è¯ï¼Ÿ",
          [
               "None", 
               "qa_chain", 
               "chat_qa_chain"
          ],
          caption = [
               "ä¸ä½¿ç”¨æ£€ç´¢å›ç­”çš„æ™®é€šæ¨¡å¼", 
               "ä¸å¸¦å†å²è®°å½•çš„æ£€ç´¢é—®ç­”æ¨¡å¼", 
               "å¸¦å†å²è®°å½•çš„æ£€ç´¢é—®ç­”æ¨¡å¼"
          ]
     )

     # ç”¨äºè·Ÿè¸ªå¯¹è¯å†å²
     # é€šè¿‡ä½¿ç”¨ st.session_state æ¥å­˜å‚¨å¯¹è¯å†å²ï¼Œ
     # å¯ä»¥åœ¨ç”¨æˆ·ä¸åº”ç”¨ç¨‹åºäº¤äº’æ—¶ä¿ç•™æ•´ä¸ªå¯¹è¯çš„ä¸Šä¸‹æ–‡
     if "messages" not in st.session_state:
          st.session_state.messages = []
     
     # å½“ç”¨æˆ·ç‚¹å‡» Submit æ—¶ï¼Œgenerate_response å°†ä½¿ç”¨ç”¨æˆ·çš„è¾“å…¥ä½œä¸ºå‚æ•°æ¥è°ƒç”¨è¯¥å‡½æ•°
     # with st.form("my_form"):
     #      text = st.text_area("Enter text:", "What are the three key pieces of advice for learning how to code?")
     #      submitted = st.form_submit_button("Submit")
     #      if not openai_api_key.startswith("sk-"):
     #           st.warning("Please enter your OpenAI API key!", icon = "")
     #      if submitted and openai_api_key.startswith("sk-"):
     #           generate_response(text, openai_api_key)
   
     messages = st.container(height = 300)
     if prompt := st.chat_input("Say something"):
          # å°†ç”¨æˆ·è¾“å…¥æ·»åŠ åˆ°å¯¹è¯å†å²ä¸­
          st.session_state.messages.appen({
               "role": "user",
               "text": prompt,
          })
          # è°ƒç”¨ respond å‡½æ•°è·å–å›ç­”
          if selected_method == "None":
               answer = generate_response(prompt, openai_api_key)
          if selected_method == "qa_chain":
               answer = get_qa_chain(prompt, openai_api_key)
          elif selected_method == "chat_qa_chain":
               answer = get_chat_qa_chain(prompt, openai_api_key)
          
          # æ£€æŸ¥å›ç­”æ˜¯å¦ä¸º None
          if answer is not None:
               # å°† LLM çš„å›ç­”æ·»åŠ åˆ°å¯¹è¯å†å²ä¸­
               st.session_state.messages.append({
                    "role": "assistant",
                    "text": answer,
               })
          
          # æ˜¾ç¤ºæ•´ä¸ªå¯¹è¯å†å²
          for message in st.session_state.messages:
               if message["role"] == "user":
                    messages.chat_message("user").write(message["text"])
               else:
                    messages.chat_message("assistant").write(message["text"])

if __name__ == "__main__":
    main()
```

### éƒ¨ç½²åº”ç”¨ç¨‹åº

è¦å°†åº”ç”¨ç¨‹åºéƒ¨ç½²åˆ° Streamlit Cloudï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š

1. ä¸ºåº”ç”¨ç¨‹åºåˆ›å»º GitHub å­˜å‚¨åº“ï¼Œå­˜å‚¨åº“åº”åŒ…å«ä¸¤ä¸ªæ–‡ä»¶ï¼š

```
your-repository/
     |_ streamlit_app.py
     |_ requirements.txt
```

2. è½¬åˆ° [Streamlit Community Cloud](https://share.streamlit.io/)ï¼Œå•å‡»å·¥ä½œåŒºä¸­çš„ `New app` æŒ‰é’®ï¼Œ
   ç„¶åæŒ‡å®šå­˜å‚¨åº“ã€åˆ†æ”¯å’Œä¸»æ–‡ä»¶è·¯å¾„ã€‚æˆ–è€…ï¼Œæ‚¨å¯ä»¥é€šè¿‡é€‰æ‹©è‡ªå®šä¹‰å­åŸŸæ¥è‡ªå®šä¹‰åº”ç”¨ç¨‹åºçš„ URLã€‚
3. ç‚¹å‡» `Deploy!` æŒ‰é’®ã€‚
4. åº”ç”¨ç¨‹åºç°åœ¨å°†éƒ¨ç½²åˆ° Streamlit Community Cloudï¼Œå¹¶ä¸”å¯ä»¥è®¿é—®åº”ç”¨ã€‚

ä¼˜åŒ–æ–¹å‘ï¼š

* ç•Œé¢ä¸­æ·»åŠ ä¸Šä¼ æœ¬åœ°æ–‡æ¡£ï¼Œå»ºç«‹å‘é‡æ•°æ®åº“çš„åŠŸèƒ½
* æ·»åŠ å¤šç§LLM ä¸ embeddingæ–¹æ³•é€‰æ‹©çš„æŒ‰é’®
* æ·»åŠ ä¿®æ”¹å‚æ•°çš„æŒ‰é’®
* æ›´å¤š...

# RAG ç»„ä»¶-LlamaIndex

# RAG ç»„ä»¶-dify




# å‚è€ƒ

* [åŠ¨æ‰‹åšä¸€ä¸ªæœ€å°RAGâ€”â€”TinyRAG](https://mp.weixin.qq.com/s?__biz=MzIyNjM2MzQyNg==&mid=2247660972&idx=1&sn=0bf6fe4d0854015d18263b49cd7b81ef&chksm=e98387af128051c9cb6914cee71626e5afb79ab8439966c508999270ca5b4048ad51a386fc2f&scene=0&xtrack=1)
* [GitHub](https://github.com/KMnO4-zx/TinyRAG)
