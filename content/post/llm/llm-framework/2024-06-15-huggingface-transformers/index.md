---
title: LLM æ¡†æ¶--Huggingface
author: ç‹å“²å³°
date: '2024-06-15'
slug: huggingface-transformers
categories:
  - llm
tags:
  - tool
---

<style>
details {
    border: 1px solid #aaa;
    border-radius: 4px;
    padding: .5em .5em 0;
}
summary {
    font-weight: bold;
    margin: -.5em -.5em 0;
    padding: .5em;
}
details[open] {
    padding: .5em;
}
details[open] summary {
    border-bottom: 1px solid #aaa;
    margin-bottom: .5em;
}
img {
    pointer-events: none;
}
</style>

<details><summary>ç›®å½•</summary><p>

- [Huggging Face NLP ecosystem](#huggging-face-nlp-ecosystem)
- [NLP ä»‹ç»](#nlp-ä»‹ç»)
- [Transformers](#transformers)
  - [ç®€ä»‹](#ç®€ä»‹)
  - [å®‰è£…](#å®‰è£…)
  - [ä½¿ç”¨](#ä½¿ç”¨)
    - [å¿«é€Ÿä¸Šæ‰‹](#å¿«é€Ÿä¸Šæ‰‹)
  - [å·¥å…· pipeline](#å·¥å…·-pipeline)
  - [Fine-tuning Pretrained Model](#fine-tuning-pretrained-model)
    - [å¤„ç†æ•°æ®](#å¤„ç†æ•°æ®)
    - [Fine-tuning model](#fine-tuning-model)
  - [åˆ†äº« Models å’Œ Tokenizers](#åˆ†äº«-models-å’Œ-tokenizers)
  - [æ¨¡å‹](#æ¨¡å‹)
- [Datasets](#datasets)
- [Tokenizers](#tokenizers)
- [Accelerate](#accelerate)
- [Hugging Face Hub](#hugging-face-hub)
- [å‚è€ƒ](#å‚è€ƒ)
</p></details><p></p>

# Huggging Face NLP ecosystem

![img](images/overview.png)

* [Transformers](https://github.com/huggingface/transformers)
* [Datasets](https://github.com/huggingface/datasets)
* [Tokenizers](https://github.com/huggingface/tokenizers)
* [Accelerate](https://github.com/huggingface/accelerate)
* [Hugging Face Hub](https://huggingface.co/models)

# NLP ä»‹ç»

NLP ä»»åŠ¡ï¼š

* **Classifying whole sentences**: Getting the sentiment of a review, detecting if an email is spam,
  determining if a sentence is grammatically correct or whether two sentences are logically related or not
* **Classifying each word in a sentence**: Identifying the grammatical components of a sentence (noun, 
  verb, adjective), or the named entities (person, location, organization)
* **Generating text content**: Completing a prompt with auto-generated text, 
  filling in the blanks in a text with masked words
* **Extracting an answer from a text**: Given a question and a context, 
  extracting the answer to the question based on the information provided in the context
* **Generating a new sentence from an input text**: Translating a text into another language, 
  summarizing a text

# Transformers

## ç®€ä»‹

* ğŸ¤— Transformers æä¾›äº†æ•°ä»¥åƒè®¡çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œæ”¯æŒ 100 å¤šç§è¯­è¨€çš„æ–‡æœ¬åˆ†ç±»ã€
  ä¿¡æ¯æŠ½å–ã€é—®ç­”ã€æ‘˜è¦ã€ç¿»è¯‘ã€æ–‡æœ¬ç”Ÿæˆã€‚å®ƒçš„å®—æ—¨æ˜¯è®©æœ€å…ˆè¿›çš„ NLP æŠ€æœ¯äººäººæ˜“ç”¨ã€‚
* ğŸ¤— Transformers æä¾›äº†ä¾¿äºå¿«é€Ÿä¸‹è½½å’Œä½¿ç”¨çš„ APIï¼Œè®©ä½ å¯ä»¥æŠŠé¢„è®­ç»ƒæ¨¡å‹ç”¨åœ¨ç»™å®šæ–‡æœ¬ã€
  åœ¨ä½ çš„æ•°æ®é›†ä¸Šå¾®è°ƒç„¶åé€šè¿‡ model hub ä¸ç¤¾åŒºå…±äº«ã€‚åŒæ—¶ï¼Œæ¯ä¸ªå®šä¹‰çš„ Python æ¨¡å—å‡å®Œå…¨ç‹¬ç«‹ï¼Œ
  æ–¹ä¾¿ä¿®æ”¹å’Œå¿«é€Ÿç ”ç©¶å®éªŒã€‚
* ğŸ¤— Transformers æ”¯æŒä¸‰ä¸ªæœ€çƒ­é—¨çš„æ·±åº¦å­¦ä¹ åº“ï¼šJax, PyTorch ä»¥åŠ TensorFlow â€” å¹¶ä¸ä¹‹æ— ç¼æ•´åˆã€‚
  ä½ å¯ä»¥ç›´æ¥ä½¿ç”¨ä¸€ä¸ªæ¡†æ¶è®­ç»ƒä½ çš„æ¨¡å‹ç„¶åç”¨å¦ä¸€ä¸ªåŠ è½½å’Œæ¨ç†ã€‚

ä¸ºä»€ä¹ˆè¦ç”¨ transformersï¼Ÿ

* ä¾¿äºä½¿ç”¨çš„å…ˆè¿›æ¨¡å‹ï¼š
    - NLU å’Œ NLG ä¸Šè¡¨ç°ä¼˜è¶Š
    - å¯¹æ•™å­¦å’Œå®è·µå‹å¥½ä¸”ä½é—¨æ§›
    - é«˜çº§æŠ½è±¡ï¼Œåªéœ€äº†è§£ä¸‰ä¸ªç±»
    - å¯¹æ‰€æœ‰æ¨¡å‹ç»Ÿä¸€çš„ API
* æ›´ä½è®¡ç®—å¼€é”€ï¼Œæ›´å°‘çš„ç¢³æ’æ”¾ï¼š
    - ç ”ç©¶äººå‘˜å¯ä»¥åˆ†äº«å·²è®­ç»ƒçš„æ¨¡å‹è€Œéæ¯æ¬¡ä»å¤´å¼€å§‹è®­ç»ƒ
    - å·¥ç¨‹å¸ˆå¯ä»¥å‡å°‘è®¡ç®—ç”¨æ—¶å’Œç”Ÿäº§ç¯å¢ƒå¼€é”€
    - æ•°åç§æ¨¡å‹æ¶æ„ã€2000 å¤šä¸ªé¢„è®­ç»ƒæ¨¡å‹ã€100 å¤šç§è¯­è¨€æ”¯æŒ
* å¯¹äºæ¨¡å‹ç”Ÿå‘½å‘¨æœŸçš„æ¯ä¸€ä¸ªéƒ¨åˆ†éƒ½é¢é¢ä¿±åˆ°ï¼š
    - è®­ç»ƒå…ˆè¿›çš„æ¨¡å‹ï¼Œåªéœ€ 3 è¡Œä»£ç 
    - æ¨¡å‹åœ¨ä¸åŒæ·±åº¦å­¦ä¹ æ¡†æ¶é—´ä»»æ„è½¬ç§»ï¼Œéšä½ å¿ƒæ„
    - ä¸ºè®­ç»ƒã€è¯„ä¼°å’Œç”Ÿäº§é€‰æ‹©æœ€é€‚åˆçš„æ¡†æ¶ï¼Œè¡”æ¥æ— ç¼
* ä¸ºä½ çš„éœ€æ±‚è½»æ¾å®šåˆ¶ä¸“å±æ¨¡å‹å’Œç”¨ä¾‹ï¼š
    - æˆ‘ä»¬ä¸ºæ¯ç§æ¨¡å‹æ¶æ„æä¾›äº†å¤šä¸ªç”¨ä¾‹æ¥å¤ç°åŸè®ºæ–‡ç»“æœ
    - æ¨¡å‹å†…éƒ¨ç»“æ„ä¿æŒé€æ˜ä¸€è‡´
    - æ¨¡å‹æ–‡ä»¶å¯å•ç‹¬ä½¿ç”¨ï¼Œæ–¹ä¾¿é­”æ”¹å’Œå¿«é€Ÿå®éªŒ

## å®‰è£…

* Python 3.8+
* PyTorch 1.11+

pip:

```bash
$ pip install transformers
```

conda:

```bash
$ conda install conda-forge::transformers
```

## ä½¿ç”¨

### å¿«é€Ÿä¸Šæ‰‹

1. ä½¿ç”¨ `pipeline` åˆ¤æ–­æ­£è´Ÿé¢æƒ…ç»ª

```python
from transformers import pipeline

classifier = pipeline("sentiment-analysis")
res1 = classifier("We are very happy to introduce pipeline to the transformers repository.")
res2 = classifier(
    ["I've been waiting for a HuggingFace course my whole life.", "I hate this so much!"]
)
print(res)
```

```
[{'label': 'POSITIVE', 'score': 0.9996980428695679}]
```

2. ä»ç»™å®šæ–‡æœ¬ä¸­æŠ½å–é—®é¢˜ç­”æ¡ˆ

```python
from transformers import pipeline

question_answerer = pipeline("question-answering")
res = question_answerer({
    "question": "What is the name of the repository ?",
    "context": "Pipeline has been included in the huggingface/transformers repository",
})
print(res)
```

3. å¯ä»¥åœ¨ä»»åŠ¡ä¸­ä¸‹è½½ã€ä¸Šä¼ ã€ä½¿ç”¨ä»»æ„é¢„è®­ç»ƒæ¨¡å‹ã€‚

```python
from transformers import AutoTokenizer, AutoModel

tokenizer = AutoTokenizer.from_pretrained("google-bert/bert-base-uncased")
model = AutoModel.from_pretrained("google-bert/bert-base-uncase")
inputs = tokenizer("Hello world!", return_tensors = "pt")
outputs = model(**inputs)
```

## å·¥å…· pipeline

> https://huggingface.co/docs/transformers/main_classes/pipelines#pipelines

å¯ç”¨çš„ pipelineï¼š

* `feature-extraction` (get the vector representation of a text)
* `fill-mask`
* `ner` (named entity recognition)
* `question-answering`
* `sentiment-analysis`
* `summarization`
* `text-generation`
* `translation`
* `zero-shot-classification`


## Fine-tuning Pretrained Model

### å¤„ç†æ•°æ®



### Fine-tuning model



## åˆ†äº« Models å’Œ Tokenizers


## æ¨¡å‹

* [æ¨¡å‹æ¶æ„](https://huggingface.co/docs/transformers/model_summary)
* [æ”¯æŒçš„æ¨¡å‹(åŒ…æ‹¬ tokenizer æ¨¡å‹)](https://huggingface.co/docs/transformers/index#supported-frameworks)

# Datasets


# Tokenizers

# Accelerate

# Hugging Face Hub


https://huggingface.co/models

# å‚è€ƒ

* [Hugging Face Transformers Github](https://github.com/huggingface/transformers/blob/main/README_zh-hans.md)
* [DeepLearning.AIâ€™s Natural Language Processing Specialization](https://www.coursera.org/specializations/natural-language-processing?utm_source=deeplearning-ai&utm_medium=institutions&utm_campaign=20211011-nlp-2-hugging_face-page-nlp-refresh)
* [fast.aiâ€™s Practical Deep Learning for Coders](https://course.fast.ai/)