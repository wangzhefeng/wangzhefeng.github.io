---
title: NLP--关键词提取
author: 王哲峰
date: '2022-04-05'
slug: nlp-keyword-extraction
categories:
  - NLP
tags:
  - tool
---

NLP--关键词提取
==========================================

1.关键词提取介绍
------------------------------------------

   关键词是代表文章重要内容的一组词。对文本聚类、分类、自动摘要等起重要作用。此外, 它还能使人们便捷地浏览和获取信息。
   类似于其他的机器学习方法, 关键词提取算法一般也可以分为有监督和无监督两类:

      - 有监督的关键词提取方法主要是通过分类的方式进行, 通过构建一个较为丰富和完善的词表, 然后通过判断每个文档与词表中每个词的匹配程度, 
        以类似打标签的方式, 达到关键词提取的效果。

         - 有监督的方法能够获取到较高的精度, 但缺点是需要大批量的标注数据, 人工成本过高

         - 另外, 现在每天的信息增加过多, 会有大量的新信息出现, 一个固定的词表有时很难将新信息的内容表达出来, 
           但是要人工维护这个受控的词表却要很高的人力成本, 这也是使用有监督方法来进行关键词提取的一个比较大的缺陷

      - 无监督的方法对数据的要求比较低, 既不需要一张人工生成、维护的词表, 也不需要人工标准语料辅助进行训练。
        因此, 这类算法在关键词提取领域的应用更受到大家的青睐。

         - TF-IDF 算法
         - TextRank 算法
         - 主题模型算法

            - LSA
            - LSI
            - LDA

2.关键词提取算法--TF-IDF 算法
------------------------------------------

   TF-IDF 算法(Term Frequency-Inverse Document Frequency, 词频-逆文档频次算法), 是一种基于统计的计算方法, 
   常用于评估一个文档集中一个词对某份文档的重要程度。这种作用显然很符合关键字抽取的需求, 一个词对文档越重要, 那就越可能
   是文档对的关键词, 常将 TF-IDF 算法应用于关键词提取中。

   从算法的名称就可以看出, TF-IDF 算法由两部分组成:

      - **TF 算法**

         - TF 算法是统计一个词在一篇文档中出现的频次, 其基本思想是, 一个词在文档中出现的次数越多, 则其对文档的表达能力就越强

      - **IDF 算法**

         - IDF 算法则是统计一个词在文档集的多少个文档中出现, 其基本思想是, 如果一个词在越少的文档中出现, 则其对文档的区分能力也就越强

   TF 算法和 IDF 算法也能单独使用, 在最早的时候就是如此, 但在使用过程中, 学者们发现这两种算法都有不足之处。TF 仅衡量词的出现频次, 
   但是没有考虑到词的对文档的区分能力。

   - TF 的计算常用表达式:

      `${tf}_{ij}=\frac{n_{ij}}{\sum_{k} n_{kj}}$` 

      `$tf(word) = \frac{word在文档中出现的次数}{文档总词数}$` 

      - 其中:

         - `$n_{ij}$` 表示词 `$i` 在文档 `$j` 中的出现频次
            
            - 但是仅用频次来表示, 长文本中的词出现频次高的概率会更大, 这一点会影响到不同文档之间关键词权值的比较, 所以在计算的过程中一般还会对词频进行归一化

         - `$\sum_{k} n_{kj}$` 是统计文档中每个词出现次数的总和, 也就是文档的总词数

   - IDF 的计算常用表达式:

      `${idf}_i=log\Big(\frac{|D|}{1+|D_{i}|}\Big)$` 

      - 其中

         - `$|D|` 为文档集中的总文档数

         - `$|D_{i}|` 为文档集中出现词 `$i` 的文档数量。分母加 1 是采用了拉普拉斯平滑, 
           避免有部分新的词没有在语料库中出现过而导致分母为零的情况出现, 增强算法的健壮性

   TF-IDF 算法就是 TF 算法与 IDF 算法的综合使用, 具体的计算方法如下:

      - `$tf \times idf(i, j) = {tf}_{ij} \times {idf}_{i} = \frac{n_{ij}}{\sum_{k} n_{kj}} \times log\Big(\frac{|D|}{1+|D_{i}|}\Big)$` 


   .. note:: 

      TF-IDF 算法也有很多变种的加权方法。传统的 TF-IDF 算法中, 仅考虑了词的两个统计信息(出现频次、在多少个文档出现), 
      因此, 其对文本的信息利用程度显然也是很少的。

      除了上面的信息外, 在一个文本中还有许多信息能够对关键词的提取起到很好的知道作用, 例如每个词的词性、出现的位置等。

      在某些特定的场景中, 如在传统的 TF-IDF 基础上, 加上这些辅助信息, 能对关键词提取的效果起到很好的提高作用。

3.关键词提取算法--TextRank 算法
------------------------------------------

   TextRank 算法的基本思想来源于 Google 的 PageRank 算法。PageRank 算法是 Google 创始人拉里·佩奇和谢尔盖·布林与 1997 年构建早期的
   的搜索系统原型时提出的链接分析算法, 该算法是他们用来评价搜索系统过覆盖网页重要性的一种重要方法, 随着 Google 的成功, 该算法也成为其他搜索
   引擎和学术界十分关注的计算模型。

   PageRank 算法是一种网页排名算法, 其基本思想有两条:

      - (1)链接数量

      - (2)链接质量

         - 一个网页被一个越高权值的网页链接, 也能表明这个网页月重要






4.关键词提取算法--LSA, LSI, LDA 算法
--------------------------------------------


5.关键词提取示例
--------------------------------------------

5.1 关键词提取使用的 Python 库
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

   - `jieba`

      - `analyse` 模块封装的 TextRank 算法

   - `gensim`

      - Gensim 是一款开源的第三方 Python 工具包, 用于从原始的非结构化文本中, 无监督的学习到文本隐层的主题向量表达。
        它支持包括 TF-IDF、LSA、LDA 和 word2vec 在内的多种主题模型算法, 支持流式训练, 并提供了诸如相似度计算, 
        信息检索等一些常用任务的 API 接口

      .. code-block:: shell

         pip install genism

5.2 关键词提取算法步骤
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

   训练一个关键词提取算法步骤:

      - 1.加载已有的文档数据集

      - 2.加载停用词表

      - 3.对数据集中的文档进行 **分词**

      - 4.根据停用词表, 过滤干扰词

      - 5.根据数据集训练关键词提取算法

   根据训练好的关键词提取算法对新文档进行关键词提取步骤:

      - 1.对新文档进行分词

      - 2.根据停用词表, 过滤干扰词

      - 3.根据训练好的算法提取关键词
